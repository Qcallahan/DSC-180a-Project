{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the main notebook I use for testing code and creating graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.1+cu121\n"
     ]
    }
   ],
   "source": [
    "# check pytorch version\n",
    "import torch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "from torch_geometric.datasets import Planetoid, TUDataset\n",
    "from torch_geometric.nn import GCN\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from sklearn.metrics import accuracy_score\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.nn import global_mean_pool\n",
    "from torch_geometric.utils import to_networkx\n",
    "from torch_geometric.nn import GINConv, global_add_pool, Sequential\n",
    "from torch_geometric.nn import GATConv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.transforms import OneHotDegree\n",
    "from torch.optim import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the datasets\n",
    "cora = Planetoid(root='/tmp/Cora', name='Cora')\n",
    "imdb = TUDataset(root=f'/tmp/IMDB-BINARY', name='IMDB-BINARY')\n",
    "enzymes = TUDataset(root=f'/tmp/ENZYMES', name='ENZYMES')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define a dict that we will use to store performance for each of our models on each dataset\n",
    "scores = {\"Cora\": {}, \"Imdb\": {}, \"Enzymes\": {}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GCN Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Node classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define a basic GCN for node classification\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(cora.num_node_features, 16)\n",
    "        self.conv2 = GCNConv(16, cora.num_classes)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the model, data, and optimizer setup in torch\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = GCN().to(device)\n",
    "data = cora[0].to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 000, Loss: 1.9532\n",
      "Epoch 020, Loss: 0.1038\n",
      "Epoch 040, Loss: 0.0140\n",
      "Epoch 060, Loss: 0.0141\n",
      "Epoch 080, Loss: 0.0167\n",
      "Epoch 100, Loss: 0.0156\n",
      "Epoch 120, Loss: 0.0139\n",
      "Epoch 140, Loss: 0.0127\n"
     ]
    }
   ],
   "source": [
    "# train model for 150 epochs\n",
    "\n",
    "model.train()\n",
    "for epoch in range(151):\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data)\n",
    "    loss = F.nll_loss(out[data.train_mask], data.y[data.train_mask])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if epoch % 20 == 0:\n",
    "        print(f'Epoch {epoch:03d}, Loss: {loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8080\n"
     ]
    }
   ],
   "source": [
    "#evaluate the model\n",
    "model.eval()\n",
    "pred = model(data).argmax(dim=1)\n",
    "correct = (pred[data.test_mask] == data.y[data.test_mask]).sum()\n",
    "acc = int(correct) / int(data.test_mask.sum())\n",
    "scores[\"Cora\"][\"GCN\"] = acc\n",
    "print(f'Accuracy: {acc:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Graph Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define a basic GCN for graph classification\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, num_node_features, num_classes):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(num_node_features, 16)\n",
    "        self.conv2 = GCNConv(16, 16)\n",
    "        self.fc = torch.nn.Linear(16, num_classes)\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x = F.relu(self.conv2(x, edge_index))\n",
    "        x = global_mean_pool(x, batch)\n",
    "        x = self.fc(x)\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper fuction to make node features for the IMDB dataset\n",
    "# We just represent each node with its degree\n",
    "def create_degree_features(data):\n",
    "    num_nodes = data.num_nodes\n",
    "    degrees = torch.bincount(data.edge_index[0], minlength=num_nodes)\n",
    "    \n",
    "    feature_vector = degrees.view(-1, 1).float()\n",
    "    \n",
    "    return feature_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to load data, train the model, and evaluate it for graph classification\n",
    "def train_and_evaluate(dataset, epochs = 150):\n",
    "\n",
    "    # Loading Data\n",
    "    train_dataset, test_dataset = train_test_split(dataset, test_size=0.2, random_state=42)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=32)\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = GCN(dataset.num_node_features or 1, dataset.num_classes).to(device)\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "    # Training\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        epoch_loss = 0\n",
    "        for data in train_loader:\n",
    "            data = data.to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # if no node features we add in the degrees\n",
    "            if data.x is None:\n",
    "                data.x = create_degree_features(data).to(device)\n",
    "\n",
    "            out = model(data.x, data.edge_index, data.batch)\n",
    "            loss = F.nll_loss(out, data.y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "        if epoch % 20 == 0:\n",
    "            print(f'Epoch {epoch}, Loss: {loss:.4f}')\n",
    "\n",
    "    # Evaluation\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for data in test_loader:\n",
    "        data = data.to(device)\n",
    "\n",
    "        # if no node features we add in the degrees\n",
    "        if data.x is None:\n",
    "            data.x = create_degree_features(data).to(device)\n",
    "\n",
    "        out = model(data.x, data.edge_index, data.batch)\n",
    "        pred = out.argmax(dim=1)\n",
    "        correct += int((pred == data.y).sum())\n",
    "        total += data.num_graphs\n",
    "\n",
    "    accuracy = correct / total\n",
    "    print(f'Accuracy: {accuracy:.4f}')\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test model on Imdb dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.6858\n",
      "Epoch 20, Loss: 0.6924\n",
      "Epoch 40, Loss: 0.6930\n",
      "Epoch 60, Loss: 0.6929\n",
      "Epoch 80, Loss: 0.7000\n",
      "Epoch 100, Loss: 0.6933\n",
      "Epoch 120, Loss: 0.6932\n",
      "Epoch 140, Loss: 0.6933\n",
      "Accuracy: 0.4800\n"
     ]
    }
   ],
   "source": [
    "scores[\"Imdb\"][\"GCN\"] = train_and_evaluate(imdb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test model on Enzymes dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 1.7994\n",
      "Epoch 20, Loss: 1.8324\n",
      "Epoch 40, Loss: 1.6149\n",
      "Epoch 60, Loss: 1.8076\n",
      "Epoch 80, Loss: 1.7449\n",
      "Epoch 100, Loss: 1.6610\n",
      "Epoch 120, Loss: 1.7488\n",
      "Epoch 140, Loss: 1.5474\n",
      "Accuracy: 0.2917\n"
     ]
    }
   ],
   "source": [
    "scores[\"Enzymes\"][\"GCN\"] = train_and_evaluate(enzymes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the scores so far"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Cora': {'GCN': 0.808},\n",
       " 'Imdb': {'GCN': 0.48},\n",
       " 'Enzymes': {'GCN': 0.2916666666666667}}"
      ]
     },
     "execution_count": 401,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GIN Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Node classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to mind max degree in dataset\n",
    "def find_max_degree(dataset):\n",
    "    max_deg = -1\n",
    "    for data in dataset:\n",
    "        max_deg = max(max_deg, data.edge_index[0].bincount().max().item())\n",
    "    return max_deg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get max of this dataset\n",
    "cora_max = find_max_degree(cora)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a transformed dataset with the one hot encoded degree features\n",
    "transformed_cora = Planetoid(root='/tmp/Cora', name='Cora', transform=OneHotDegree(cora_max))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define a GIN for node classification\n",
    "class GIN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.mlp1 = torch.nn.Sequential(\n",
    "            torch.nn.Linear(transformed_cora.num_node_features, 16),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(16, 16)\n",
    "        )\n",
    "        self.mlp2 = torch.nn.Sequential(\n",
    "            torch.nn.Linear(16, 16),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(16, transformed_cora.num_classes)\n",
    "        )\n",
    "        \n",
    "        self.conv1 = GINConv(self.mlp1, eps=0.0, train_eps=True)\n",
    "        self.conv2 = GINConv(self.mlp2, eps=0.0, train_eps=True)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the model, data, and optimizer setup in torch\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = GIN().to(device)\n",
    "data = transformed_cora[0].to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 000, Loss: 1.9446\n",
      "Epoch 020, Loss: 0.0206\n",
      "Epoch 040, Loss: 0.0002\n",
      "Epoch 060, Loss: 0.0001\n",
      "Epoch 080, Loss: 0.0002\n",
      "Epoch 100, Loss: 0.0003\n",
      "Epoch 120, Loss: 0.0004\n",
      "Epoch 140, Loss: 0.0005\n"
     ]
    }
   ],
   "source": [
    "# train model for 150 epochs\n",
    "\n",
    "model.train()\n",
    "for epoch in range(151):\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data)\n",
    "    loss = F.nll_loss(out[data.train_mask], data.y[data.train_mask])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if epoch % 20 == 0:\n",
    "        print(f'Epoch {epoch:03d}, Loss: {loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7390\n"
     ]
    }
   ],
   "source": [
    "#evaluate the model\n",
    "model.eval()\n",
    "pred = model(data).argmax(dim=1)\n",
    "correct = (pred[data.test_mask] == data.y[data.test_mask]).sum()\n",
    "acc = int(correct) / int(data.test_mask.sum())\n",
    "scores[\"Cora\"][\"GIN\"] = acc\n",
    "print(f'Accuracy: {acc:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Graph Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define a GIN for node classification\n",
    "class GIN(torch.nn.Module):\n",
    "    def __init__(self, num_node_features, num_classes):\n",
    "        super().__init__()\n",
    "\n",
    "        self.mlp1 = torch.nn.Sequential(\n",
    "            torch.nn.Linear(num_node_features, 16),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(16, 16)\n",
    "        )\n",
    "        self.mlp2 = torch.nn.Sequential(\n",
    "            torch.nn.Linear(16, 16),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(16, 16)\n",
    "        )\n",
    "\n",
    "        self.conv1 = GINConv(self.mlp1, eps=0.0, train_eps=True)\n",
    "        self.conv2 = GINConv(self.mlp2, eps=0.0, train_eps=True)\n",
    "\n",
    "        self.fc = torch.nn.Sequential(\n",
    "            torch.nn.Linear(16, 16),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(16, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = global_add_pool(x, batch)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get max degrees for our datasets\n",
    "imdb_max = find_max_degree(imdb)\n",
    "enzymes_max = find_max_degree(enzymes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a transformed datasets with the one hot encoded degree features\n",
    "transformed_imdb = TUDataset(root='/tmp/IMDB', name='IMDB-BINARY', transform=OneHotDegree(imdb_max))\n",
    "transformed_enzymes = TUDataset(root='/tmp/ENZYMES', name='ENZYMES', transform=OneHotDegree(enzymes_max))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to load data, train the model, and evaluate it for graph classification\n",
    "def train_and_evaluate(dataset, epochs = 150):\n",
    "\n",
    "    # Loading Data\n",
    "    train_dataset, test_dataset = train_test_split(dataset, test_size=0.2, random_state=42)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=32)\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = GIN(dataset.num_node_features or 1, dataset.num_classes).to(device)\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "    # Training\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        epoch_loss = 0\n",
    "        for data in train_loader:\n",
    "            data = data.to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            out = model(data.x, data.edge_index, data.batch)\n",
    "            loss = F.nll_loss(out, data.y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "        if epoch % 20 == 0:\n",
    "            print(f'Epoch {epoch}, Loss: {loss:.4f}')\n",
    "\n",
    "    # Evaluation\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for data in test_loader:\n",
    "        data = data.to(device)\n",
    "        out = model(data.x, data.edge_index, data.batch)\n",
    "        pred = out.argmax(dim=1)\n",
    "        correct += int((pred == data.y).sum())\n",
    "        total += data.num_graphs\n",
    "\n",
    "    accuracy = correct / total\n",
    "    print(f'Accuracy: {accuracy:.4f}')\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.5068\n",
      "Epoch 20, Loss: 0.3577\n",
      "Epoch 40, Loss: 0.3429\n",
      "Epoch 60, Loss: 0.4972\n",
      "Epoch 80, Loss: 0.4678\n",
      "Epoch 100, Loss: 0.4371\n",
      "Epoch 120, Loss: 0.1724\n",
      "Epoch 140, Loss: 0.4931\n",
      "Accuracy: 0.7100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.71"
      ]
     },
     "execution_count": 413,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_and_evaluate(transformed_imdb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.5782\n",
      "Epoch 20, Loss: 0.3879\n",
      "Epoch 40, Loss: 0.3268\n",
      "Epoch 60, Loss: 0.3407\n",
      "Epoch 80, Loss: 0.2464\n",
      "Epoch 100, Loss: 0.2655\n",
      "Epoch 120, Loss: 0.3316\n",
      "Epoch 140, Loss: 0.2222\n",
      "Accuracy: 0.7500\n"
     ]
    }
   ],
   "source": [
    "# Test model on Imdb dataset\n",
    "scores[\"Imdb\"][\"GIN\"] = train_and_evaluate(transformed_imdb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 1.8111\n",
      "Epoch 20, Loss: 1.6782\n",
      "Epoch 40, Loss: 1.5854\n",
      "Epoch 60, Loss: 1.3291\n",
      "Epoch 80, Loss: 1.1300\n",
      "Epoch 100, Loss: 1.2712\n",
      "Epoch 120, Loss: 1.0763\n",
      "Epoch 140, Loss: 0.9789\n",
      "Accuracy: 0.4083\n"
     ]
    }
   ],
   "source": [
    "# Test model on Enzymes dataset\n",
    "scores[\"Enzymes\"][\"GIN\"] = train_and_evaluate(transformed_enzymes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Cora': {'GCN': 0.808, 'GIN': 0.739},\n",
       " 'Imdb': {'GCN': 0.48, 'GIN': 0.75},\n",
       " 'Enzymes': {'GCN': 0.2916666666666667, 'GIN': 0.4083333333333333}}"
      ]
     },
     "execution_count": 416,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GAT Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Node classification GCN baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We define a new GCN that can handle a dynamic number of layers\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, num_layers):\n",
    "        super().__init__()\n",
    "        self.convs = torch.nn.ModuleList()\n",
    "        self.convs.append(GCNConv(in_channels, hidden_channels))\n",
    "        for _ in range(num_layers - 2):\n",
    "            self.convs.append(GCNConv(hidden_channels, hidden_channels))\n",
    "        self.convs.append(GCNConv(hidden_channels, out_channels))\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        for conv in self.convs[:-1]:\n",
    "            x = conv(x, edge_index)\n",
    "            x = F.relu(x)\n",
    "        x = self.convs[-1](x, edge_index)\n",
    "        \n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we turn everything into neat helper functions since we are going to be training a lot of models here\n",
    "\n",
    "def train_model(model, data, optimizer, num_epochs=100):\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data)\n",
    "        loss = F.nll_loss(out[data.train_mask], data.y[data.train_mask])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    return model\n",
    "\n",
    "def evaluate_model(model, data):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        pred = model(data).argmax(dim=1)\n",
    "        train_correct = (pred[data.train_mask] == data.y[data.train_mask]).sum()\n",
    "        val_correct = (pred[data.val_mask] == data.y[data.val_mask]).sum()\n",
    "        test_correct = (pred[data.test_mask] == data.y[data.test_mask]).sum()\n",
    "        \n",
    "        train_acc = float(train_correct) / int(data.train_mask.sum())\n",
    "        val_acc = float(val_correct) / int(data.val_mask.sum())\n",
    "        test_acc = float(test_correct) / int(data.test_mask.sum())\n",
    "        \n",
    "    return train_acc, val_acc, test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model with 1 layers\n",
      "Training model with 2 layers\n",
      "Training model with 3 layers\n",
      "Training model with 4 layers\n",
      "Training model with 5 layers\n",
      "Training model with 6 layers\n",
      "Training model with 7 layers\n",
      "Training model with 8 layers\n",
      "Training model with 9 layers\n",
      "Training model with 10 layers\n",
      "Training model with 11 layers\n",
      "Training model with 12 layers\n",
      "Training model with 13 layers\n",
      "Training model with 14 layers\n",
      "Training model with 15 layers\n",
      "\n",
      "==================================================\n",
      "Summary of Results\n",
      "==================================================\n",
      "\n",
      "Number of Layers | Train Acc | Val Acc | Test Acc\n",
      "--------------------------------------------------\n",
      "             1 | 1.0000 | 0.7760 | 0.8090\n",
      "             2 | 1.0000 | 0.7840 | 0.7960\n",
      "             3 | 1.0000 | 0.7860 | 0.8160\n",
      "             4 | 1.0000 | 0.7580 | 0.7680\n",
      "             5 | 1.0000 | 0.7460 | 0.7450\n",
      "             6 | 1.0000 | 0.7240 | 0.7360\n",
      "             7 | 1.0000 | 0.7240 | 0.7240\n",
      "             8 | 1.0000 | 0.6880 | 0.7070\n",
      "             9 | 1.0000 | 0.6880 | 0.6780\n",
      "            10 | 0.8429 | 0.5120 | 0.5570\n",
      "            11 | 0.3571 | 0.2100 | 0.1800\n",
      "            12 | 0.6929 | 0.3840 | 0.4300\n",
      "            13 | 0.6357 | 0.4160 | 0.4130\n",
      "            14 | 0.3071 | 0.2340 | 0.2430\n",
      "            15 | 0.3929 | 0.3280 | 0.3280\n"
     ]
    }
   ],
   "source": [
    "# Test different numbers of layers\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "data = cora[0].to(device)\n",
    "\n",
    "results = {}\n",
    "for num_layers in range(1, 16):\n",
    "    print(f\"Training model with {num_layers} layers\")\n",
    "    \n",
    "    model = GCN(\n",
    "        in_channels=cora.num_node_features,\n",
    "        hidden_channels=16,\n",
    "        out_channels=cora.num_classes,\n",
    "        num_layers=num_layers\n",
    "    ).to(device)\n",
    "    \n",
    "    optimizer = Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "    \n",
    "    model = train_model(model, data, optimizer)\n",
    "    \n",
    "    train_acc, val_acc, test_acc = evaluate_model(model, data)\n",
    "    \n",
    "    results[num_layers] = {\n",
    "        'train_acc': train_acc,\n",
    "        'val_acc': val_acc,\n",
    "        'test_acc': test_acc\n",
    "    }\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Summary of Results\")\n",
    "print(\"=\"*50)\n",
    "print(\"\\nNumber of Layers | Train Acc | Val Acc | Test Acc\")\n",
    "print(\"-\"*50)\n",
    "for layers in range(1, 16):\n",
    "    r = results[layers]\n",
    "    print(f\"{layers:14d} | {r['train_acc']:.4f} | {r['val_acc']:.4f} | {r['test_acc']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Node classification GAT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAT(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, num_layers, heads=8):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.convs = torch.nn.ModuleList()\n",
    "        \n",
    "        self.convs.append(GATConv(\n",
    "            in_channels, \n",
    "            hidden_channels, \n",
    "            heads=heads, \n",
    "            concat=True, \n",
    "        ))\n",
    "        \n",
    "        hidden_in_channels = hidden_channels * heads\n",
    "        for _ in range(num_layers - 2):\n",
    "            self.convs.append(GATConv(\n",
    "                hidden_in_channels,\n",
    "                hidden_channels,\n",
    "                heads=heads,\n",
    "                concat=True,\n",
    "            ))\n",
    "            \n",
    "        self.convs.append(GATConv(\n",
    "            hidden_in_channels,\n",
    "            out_channels,\n",
    "            heads=heads,\n",
    "            concat=False,\n",
    "        ))\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        for conv in self.convs[:-1]:\n",
    "            x = F.elu(conv(x, edge_index))\n",
    "        x = self.convs[-1](x, edge_index)\n",
    "        \n",
    "        return F.log_softmax(x, dim=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model with 1 layers\n",
      "Training model with 2 layers\n",
      "Training model with 3 layers\n",
      "Training model with 4 layers\n",
      "Training model with 5 layers\n",
      "Training model with 6 layers\n",
      "Training model with 7 layers\n",
      "Training model with 8 layers\n",
      "Training model with 9 layers\n",
      "Training model with 10 layers\n",
      "Training model with 11 layers\n",
      "Training model with 12 layers\n",
      "Training model with 13 layers\n",
      "Training model with 14 layers\n",
      "Training model with 15 layers\n",
      "\n",
      "==================================================\n",
      "Summary of Results\n",
      "==================================================\n",
      "\n",
      "Number of Layers | Train Acc | Val Acc | Test Acc\n",
      "--------------------------------------------------\n",
      "             1 | 1.0000 | 0.7460 | 0.7840\n",
      "             2 | 1.0000 | 0.7440 | 0.7920\n",
      "             3 | 1.0000 | 0.7600 | 0.7980\n",
      "             4 | 1.0000 | 0.7700 | 0.7880\n",
      "             5 | 1.0000 | 0.7700 | 0.7640\n",
      "             6 | 1.0000 | 0.7640 | 0.7710\n",
      "             7 | 1.0000 | 0.7520 | 0.7530\n",
      "             8 | 1.0000 | 0.7700 | 0.7700\n",
      "             9 | 1.0000 | 0.7540 | 0.7700\n",
      "            10 | 1.0000 | 0.7580 | 0.7560\n",
      "            11 | 0.3571 | 0.3120 | 0.3080\n",
      "            12 | 1.0000 | 0.7160 | 0.7340\n",
      "            13 | 1.0000 | 0.7300 | 0.7490\n",
      "            14 | 0.6643 | 0.4720 | 0.4870\n",
      "            15 | 0.1429 | 0.1560 | 0.1420\n"
     ]
    }
   ],
   "source": [
    "# Test different numbers of layers\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "data = cora[0].to(device)\n",
    "\n",
    "results = {}\n",
    "for num_layers in range(1, 16):\n",
    "    print(f\"Training model with {num_layers} layers\")\n",
    "    \n",
    "    model = GAT(\n",
    "        in_channels=cora.num_node_features,\n",
    "        hidden_channels=16,\n",
    "        out_channels=cora.num_classes,\n",
    "        num_layers=num_layers\n",
    "    ).to(device)\n",
    "    \n",
    "    optimizer = Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "    \n",
    "    model = train_model(model, data, optimizer)\n",
    "    \n",
    "    train_acc, val_acc, test_acc = evaluate_model(model, data)\n",
    "    \n",
    "    results[num_layers] = {\n",
    "        'train_acc': train_acc,\n",
    "        'val_acc': val_acc,\n",
    "        'test_acc': test_acc\n",
    "    }\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Summary of Results\")\n",
    "print(\"=\"*50)\n",
    "print(\"\\nNumber of Layers | Train Acc | Val Acc | Test Acc\")\n",
    "print(\"-\"*50)\n",
    "for layers in range(1, 16):\n",
    "    r = results[layers]\n",
    "    print(f\"{layers:14d} | {r['train_acc']:.4f} | {r['val_acc']:.4f} | {r['test_acc']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Cora': {'GCN': 0.808, 'GIN': 0.739},\n",
       " 'Imdb': {'GCN': 0.48, 'GIN': 0.75},\n",
       " 'Enzymes': {'GCN': 0.2916666666666667, 'GIN': 0.4083333333333333}}"
      ]
     },
     "execution_count": 424,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
