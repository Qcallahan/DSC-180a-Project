{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the main notebook I use for testing code and creating graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.1+cu121\n"
     ]
    }
   ],
   "source": [
    "# check pytorch version\n",
    "import torch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "from torch_geometric.datasets import Planetoid, TUDataset\n",
    "from torch_geometric.nn import GCN\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from sklearn.metrics import accuracy_score\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.nn import global_mean_pool\n",
    "from torch_geometric.utils import to_networkx\n",
    "from torch_geometric.nn import GINConv, global_add_pool, Sequential\n",
    "from torch_geometric.nn import GATConv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.transforms import OneHotDegree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the datasets\n",
    "cora = Planetoid(root='/tmp/Cora', name='Cora')\n",
    "imdb = TUDataset(root=f'/tmp/IMDB-BINARY', name='IMDB-BINARY')\n",
    "enzymes = TUDataset(root=f'/tmp/ENZYMES', name='ENZYMES')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define a dict that we will use to store performance for each of our models on each dataset\n",
    "scores = {\"Cora\": {}, \"Imdb\": {}, \"Enzymes\": {}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GCN Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Node classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define a basic GCN for node classification\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(cora.num_node_features, 16)\n",
    "        self.conv2 = GCNConv(16, cora.num_classes)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the model, data, and optimizer setup in torch\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = GCN().to(device)\n",
    "data = cora[0].to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 000, Loss: 1.9566\n",
      "Epoch 020, Loss: 0.2462\n",
      "Epoch 040, Loss: 0.0478\n",
      "Epoch 060, Loss: 0.0686\n",
      "Epoch 080, Loss: 0.0372\n",
      "Epoch 100, Loss: 0.0409\n",
      "Epoch 120, Loss: 0.0305\n",
      "Epoch 140, Loss: 0.0328\n"
     ]
    }
   ],
   "source": [
    "# train model for 150 epochs\n",
    "\n",
    "model.train()\n",
    "for epoch in range(151):\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data)\n",
    "    loss = F.nll_loss(out[data.train_mask], data.y[data.train_mask])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if epoch % 20 == 0:\n",
    "        print(f'Epoch {epoch:03d}, Loss: {loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7960\n"
     ]
    }
   ],
   "source": [
    "#evaluate the model\n",
    "model.eval()\n",
    "pred = model(data).argmax(dim=1)\n",
    "correct = (pred[data.test_mask] == data.y[data.test_mask]).sum()\n",
    "acc = int(correct) / int(data.test_mask.sum())\n",
    "scores[\"Cora\"][\"GCN\"] = acc\n",
    "print(f'Accuracy: {acc:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Graph Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define a basic GCN for graph classification\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, num_node_features, num_classes):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(num_node_features, 16)\n",
    "        self.conv2 = GCNConv(16, 16)\n",
    "        self.fc = torch.nn.Linear(16, num_classes)\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x = F.relu(self.conv2(x, edge_index))\n",
    "        x = global_mean_pool(x, batch)\n",
    "        x = self.fc(x)\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper fuction to make node features for the IMDB dataset\n",
    "# We just represent each node with its degree\n",
    "def create_degree_features(data):\n",
    "    num_nodes = data.num_nodes\n",
    "    degrees = torch.bincount(data.edge_index[0], minlength=num_nodes)\n",
    "    \n",
    "    feature_vector = degrees.view(-1, 1).float()\n",
    "    \n",
    "    return feature_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to load data, train the model, and evaluate it for graph classification\n",
    "def train_and_evaluate(dataset, epochs = 150):\n",
    "\n",
    "    # Loading Data\n",
    "    train_dataset, test_dataset = train_test_split(dataset, test_size=0.2, random_state=42)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=32)\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = GCN(dataset.num_node_features or 1, dataset.num_classes).to(device)\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "    # Training\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        epoch_loss = 0\n",
    "        for data in train_loader:\n",
    "            data = data.to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # if no node features we add in the degrees\n",
    "            if data.x is None:\n",
    "                data.x = create_degree_features(data).to(device)\n",
    "\n",
    "            out = model(data.x, data.edge_index, data.batch)\n",
    "            loss = F.nll_loss(out, data.y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "        if epoch % 20 == 0:\n",
    "            print(f'Epoch {epoch}, Loss: {loss:.4f}')\n",
    "\n",
    "    # Evaluation\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for data in test_loader:\n",
    "        data = data.to(device)\n",
    "\n",
    "        # if no node features we add in the degrees\n",
    "        if data.x is None:\n",
    "            data.x = create_degree_features(data).to(device)\n",
    "\n",
    "        out = model(data.x, data.edge_index, data.batch)\n",
    "        pred = out.argmax(dim=1)\n",
    "        correct += int((pred == data.y).sum())\n",
    "        total += data.num_graphs\n",
    "\n",
    "    accuracy = correct / total\n",
    "    print(f'Accuracy: {accuracy:.4f}')\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test model on Imdb dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.6746\n",
      "Epoch 20, Loss: 0.6701\n",
      "Epoch 40, Loss: 0.7241\n",
      "Epoch 60, Loss: 0.4621\n",
      "Epoch 80, Loss: 0.5995\n",
      "Epoch 100, Loss: 0.7216\n",
      "Epoch 120, Loss: 0.4611\n",
      "Epoch 140, Loss: 0.4974\n",
      "Accuracy: 0.6600\n"
     ]
    }
   ],
   "source": [
    "scores[\"Imdb\"][\"GCN\"] = train_and_evaluate(imdb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test model on Enzymes dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 1.7942\n",
      "Epoch 20, Loss: 1.7589\n",
      "Epoch 40, Loss: 1.6636\n",
      "Epoch 60, Loss: 1.6799\n",
      "Epoch 80, Loss: 1.7140\n",
      "Epoch 100, Loss: 1.5424\n",
      "Epoch 120, Loss: 1.7926\n",
      "Epoch 140, Loss: 1.5380\n",
      "Accuracy: 0.2583\n"
     ]
    }
   ],
   "source": [
    "scores[\"Enzymes\"][\"GCN\"] = train_and_evaluate(enzymes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the scores so far"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Cora': {'GCN': 0.796},\n",
       " 'Imdb': {'GCN': 0.66},\n",
       " 'Enzymes': {'GCN': 0.25833333333333336}}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GIN Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Node classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to mind max degree in dataset\n",
    "def find_max_degree(dataset):\n",
    "    max_degree = -1\n",
    "    for data in dataset:\n",
    "        degree = data.edge_index[0].bincount().max().item()\n",
    "        if degree > max_degree:\n",
    "            max_degree = degree\n",
    "            return max_degree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get max of this dataset\n",
    "cora_max = find_max_degree(cora)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a transformed dataset with the one hot encoded degree features\n",
    "transformed_cora = Planetoid(root='/tmp/Cora', name='Cora', transform=OneHotDegree(cora_max))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define a GIN for node classification\n",
    "class GIN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.mlp1 = torch.nn.Sequential(\n",
    "            torch.nn.Linear(transformed_cora.num_node_features, 16),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(16, 16)\n",
    "        )\n",
    "        self.mlp2 = torch.nn.Sequential(\n",
    "            torch.nn.Linear(16, 16),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(16, transformed_cora.num_classes)\n",
    "        )\n",
    "        \n",
    "        self.conv1 = GINConv(self.mlp1, eps=0.0, train_eps=True)\n",
    "        self.conv2 = GINConv(self.mlp2, eps=0.0, train_eps=True)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)        \n",
    "        x = self.conv2(x, edge_index)\n",
    "\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the model, data, and optimizer setup in torch\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = GIN().to(device)\n",
    "data = transformed_cora[0].to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 000, Loss: 1.9842\n",
      "Epoch 020, Loss: 0.7392\n",
      "Epoch 040, Loss: 0.1852\n",
      "Epoch 060, Loss: 0.1175\n",
      "Epoch 080, Loss: 0.0528\n",
      "Epoch 100, Loss: 0.0361\n",
      "Epoch 120, Loss: 0.0334\n",
      "Epoch 140, Loss: 0.0227\n"
     ]
    }
   ],
   "source": [
    "# train model for 150 epochs\n",
    "\n",
    "model.train()\n",
    "for epoch in range(151):\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data)\n",
    "    loss = F.nll_loss(out[data.train_mask], data.y[data.train_mask])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if epoch % 20 == 0:\n",
    "        print(f'Epoch {epoch:03d}, Loss: {loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7090\n"
     ]
    }
   ],
   "source": [
    "#evaluate the model\n",
    "model.eval()\n",
    "pred = model(data).argmax(dim=1)\n",
    "correct = (pred[data.test_mask] == data.y[data.test_mask]).sum()\n",
    "acc = int(correct) / int(data.test_mask.sum())\n",
    "scores[\"Cora\"][\"GIN\"] = acc\n",
    "print(f'Accuracy: {acc:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Graph Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define a GIN for node classification\n",
    "class GIN(torch.nn.Module):\n",
    "    def __init__(self, num_node_features, num_classes):\n",
    "        super().__init__()\n",
    "\n",
    "        self.mlp1 = torch.nn.Sequential(\n",
    "            torch.nn.Linear(num_node_features, 16),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(16, 16)\n",
    "        )\n",
    "        self.mlp2 = torch.nn.Sequential(\n",
    "            torch.nn.Linear(16, 16),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(16, 16)\n",
    "        )\n",
    "\n",
    "        self.conv1 = GINConv(self.mlp1, eps=0.0, train_eps=True)\n",
    "        self.conv2 = GINConv(self.mlp2, eps=0.0, train_eps=True)\n",
    "\n",
    "        self.fc = torch.nn.Sequential(\n",
    "            torch.nn.Linear(16, 16),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(16, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = global_add_pool(x, batch)\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.fc1(x)\n",
    "\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get max degrees for our datasets\n",
    "def find_max_degree(dataset):\n",
    "    max_degree = 0\n",
    "    for data in dataset:\n",
    "        max_degree = max(max_degree, int(data.edge_index.max()))\n",
    "    return max_degree\n",
    "\n",
    "imdb_max = find_max_degree(imdb)\n",
    "enzymes_max = find_max_degree(enzymes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a transformed datasets with the one hot encoded degree features\n",
    "transformed_imdb = TUDataset(root='/tmp/IMDB', name='IMDB-BINARY', transform=OneHotDegree(imdb_max))\n",
    "transformed_enzymes = TUDataset(root='/tmp/ENZYMES', name='ENZYMES', transform=OneHotDegree(enzymes_max))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to load data, train the model, and evaluate it for graph classification\n",
    "def train_and_evaluate(dataset, epochs = 150):\n",
    "\n",
    "    # Loading Data\n",
    "    train_dataset, test_dataset = train_test_split(dataset, test_size=0.2, random_state=42)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=32)\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = GIN(dataset.num_node_features or 1, dataset.num_classes).to(device)\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "    # Training\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        epoch_loss = 0\n",
    "        for data in train_loader:\n",
    "            data = data.to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            out = model(data.x, data.edge_index, data.batch)\n",
    "            loss = F.nll_loss(out, data.y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "        if epoch % 20 == 0:\n",
    "            print(f'Epoch {epoch}, Loss: {loss:.4f}')\n",
    "\n",
    "    # Evaluation\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for data in test_loader:\n",
    "        data = data.to(device)\n",
    "        out = model(data.x, data.edge_index, data.batch)\n",
    "        pred = out.argmax(dim=1)\n",
    "        correct += int((pred == data.y).sum())\n",
    "        total += data.num_graphs\n",
    "\n",
    "    accuracy = correct / total\n",
    "    print(f'Accuracy: {accuracy:.4f}')\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "GIN.forward() takes 2 positional arguments but 4 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[33], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtrain_and_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtransformed_imdb\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[32], line 23\u001b[0m, in \u001b[0;36mtrain_and_evaluate\u001b[1;34m(dataset, epochs)\u001b[0m\n\u001b[0;32m     20\u001b[0m data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     21\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 23\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     24\u001b[0m loss \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mnll_loss(out, data\u001b[38;5;241m.\u001b[39my)\n\u001b[0;32m     25\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32mc:\\Users\\quent\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\quent\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: GIN.forward() takes 2 positional arguments but 4 were given"
     ]
    }
   ],
   "source": [
    "train_and_evaluate(transformed_imdb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Cora': {'GCN': 0.807, 'GIN': 0.737},\n",
       " 'Imdb': {'GCN': 0.72},\n",
       " 'Enzymes': {'GCN': 0.2833333333333333}}"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
